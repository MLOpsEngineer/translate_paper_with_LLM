0
"Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. GPT"
"Understands, Too.
arXiv:2103.10385 [cs], March 2021. URL http://arxiv.org/abs/"
2103.10385. arXiv: 2103.10385.
"Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike"
"Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining"
"approach, 2019."
"arXiv
preprint
Ilya Loshchilov
and Frank Hutter.
Decoupled weight
decay
regularization."
"arXiv:1711.05101, 2017."
"Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2019."
"Rabeeh Karimi Mahabadi, James Henderson, and Sebastian Ruder. Compacter: Efﬁcient
low-rank"
"hypercomplex adapter layers, 2021."
"Linyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad, Chiachun Hsieh,"
"Xiangru Tang, Aadit Vyas, Neha Verma, Pranav Krishna, et al. Dart: Open-domain structured"
"data record to text generation. arXiv preprint arXiv:2007.02871, 2020."
"Jekaterina Novikova, Ondˇrej Duˇsek, and Verena Rieser. The e2e dataset: New challenges for end-"
"to-end generation. arXiv preprint arXiv:1706.09254, 2017."
"Samet Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi.
Generalization guaran-"
"arXiv preprint
tees for neural networks via harnessing the low-rank structure of
the jacobian."
"arXiv:1906.05392, 2019."
"Jonas Pfeiffer, Aishwarya Kamath, Andreas R¨uckl´e, Kyunghyun Cho, and Iryna Gurevych. Adapter-"
"fusion: Non-destructive task composition for transfer learning, 2021."
"Daniel Povey, Gaofeng Cheng, Yiming Wang, Ke Li, Hainan Xu, Mahsa Yarmohammadi, and San-"
"jeev Khudanpur.
Semi-orthogonal
low-rank matrix factorization for deep neural networks.
In"
"Interspeech, pp. 3743–3747, 2018."
"Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving Language Under-"
"standing by Generative Pre-Training. pp.
12, a."
"Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language"
"Models are Unsupervised Multitask Learners. pp.
24, b."
"Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable questions"
"for squad. CoRR, abs/1806.03822, 2018. URL http://arxiv.org/abs/1806.03822."
"Sylvestre-Alvise Rebufﬁ, Hakan Bilen, and Andrea Vedaldi. Learning multiple visual domains with"
"residual adapters. arXiv:1705.08045 [cs, stat], November 2017. URL http://arxiv.org/"
abs/1705.08045. arXiv: 1705.08045.
"Andreas R¨uckl´e, Gregor Geigle, Max Glockner, Tilman Beck,
Jonas Pfeiffer, Nils Reimers, and"
"Iryna Gurevych. Adapterdrop: On the efﬁciency of adapters in transformers, 2020."
"Tara N Sainath, Brian Kingsbury, Vikas Sindhwani, Ebru Arisoy, and Bhuvana Ramabhadran. Low-"
"rank matrix factorization for deep neural network training with high-dimensional output
targets."
"In 2013 IEEE international conference on acoustics, speech and signal processing, pp. 6655–"
"6659. IEEE, 2013."
"Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley,
Jared Casper,
and Bryan"
"Catanzaro. Megatron-lm: Training multi-billion parameter
language models using model par-"
"allelism, 2020."
"Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng,"
and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment
"the 2013 Conference on Empirical Methods in Natural Language
treebank.
In Proceedings of"
"Processing, pp. 1631–1642, Seattle, Washington, USA, October 2013. Association for Computa-"
tional Linguistics. URL https://aclanthology.org/D13-1170.
