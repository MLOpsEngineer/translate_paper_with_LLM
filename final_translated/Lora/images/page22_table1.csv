0,1,2,3,4,5,6,7,8,9
Method,,,,WebNLG,,,,,
,,BLEU↑,,,MET↑,,,TER↓,
,U,S,A,U,S,A,U,S,A
,,,,GPT-2 Medium,,,,,
Fine-Tune (354M),27.7,64.2,46.5,.30,.45,.38,.76,.33,.53
AdapterL (0.37M),45.1,54.5,50.2,.36,.39,.38,.46,.40,.43
AdapterL (11M),48.3,60.4,54.9,.38,.43,.41,.45,.35,.39
FTTop2 (24M),18.9,53.6,36.0,.23,.38,.31,.99,.49,.72
Preﬁx (0.35M),45.6,62.9,55.1,.38,.44,.41,.49,.35,.40
LoRA (0.35M),46.7±.4,62.1±.2,55.3±.2,.38,.44,.41,.46,.33,.39
,,,,GPT-2 Large,,,,,
Fine-Tune (774M),43.1,65.3,55.5,.38,.46,.42,.53,.33,.42
AdapterL (0.88M),49.8±.0,61.1±.0,56.0±.0,.38,.43,.41,.44,.35,.39
AdapterL (23M),49.2±.1,64.7±.2,57.7±.1,.39,.46,.43,.46,.33,.39
Preﬁx (0.77M),47.7,63.4,56.3,.39,.45,.42,.48,.34,.40
LoRA (0.77M),48.4±.3,64.0±.3,57.0±.1,.39,.45,.42,.45,.32,.38
