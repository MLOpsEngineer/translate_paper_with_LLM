**소개**

안녕하세요 여러분, 제 새로운 LLaMA에 대한 비디오에 오신 것을 환영합니다. 
이 비디오에서는 LLaMA가 무엇인지, 어떻게 만들어졌는지, Transformer와 구조적으로 어떻게 다른지 살펴볼 것입니다. 우리는 LLaMA를 구성하는 각 블록을 구축해볼 것이며, 각 블록이 무엇을 하는지 개념적으로 설명할 뿐만 아니라 수학적 관점과 코딩 관점에서도 탐구하여 이론과 실습을 통합해 보겠습니다. 이 비디오를 보시면 LLaMA 모델이 어떻게 구성되어 있는지 깊이 이해하게 되실 것입니다. 블록들이 서로 어떻게 상호작용하는지뿐만 아니라, 그들이 어떻게 작동하고 처음에 왜 이러한 블록이 필요한지도 이해하게 될 것입니다.

이번 비디오에서는 많은 주제를 다룰 것입니다. 먼저 일반적인 Transformer와 LLaMA 모델 사이의 아키텍처적 차이부터 시작하겠습니다. 우리는 새로운 정규화인 RMSNorm, Rotary Positional Embedding, KV 캐시, Multi-Query Attention, Grouped Query Attention, 그리고 Feed Forward 레이어의 SwiGLU 활성화 함수에 대해 살펴볼 것입니다. 물론 여러분이 어느 정도의 배경 지식을 가지고 있다고 가정합니다. 우선, Transformer가 어떻게 작동하는지 알아야 하기 때문에 제 이전의 Transformer에 대한 비디오를 시청하시길 강력히 추천합니다. 이전 비디오에서는 Transformer 모델의 트레이닝과 추론 개념도 탐구했습니다. 약 45분 분량이며, Transformer에 대한 깊은 이해를 제공하므로 볼 가치가 있다고 생각합니다. 그 지식을 갖춘 후에 이 비디오를 보시면 됩니다. 이미 그 비디오를 보셨지만 몇 가지를 잊으셨다면, 진행하면서 대부분의 개념을 다시 리뷰할 것이므로 걱정하지 않으셔도 됩니다. 또한 기본적인 선형대수학 지식, 예를 들어 행렬 곱셈이나 내적 등의 기본 사항을 알고 계시리라 믿습니다. 그리고 우리는 Rotary Positional Embedding을 사용할 것이므로 복소수에 대한 약간의 지식도 필요하지만, 필수적이지는 않습니다. 복소수를 기억하지 못하더라도 개념을 이해하는 데 문제없으니 걱정하지 마세요.

가끔은 여러분이 이미 익숙한 주제를 리뷰할 수도 있으니, 해당 부분은 자유롭게 건너뛰셔도 됩니다.

**Transformer와 LLaMA의 비교**

이 그림은 제가 오른쪽에 직접 만든 것인데, 논문에서 아키텍처 이미지를 찾을 수 없었기 때문입니다. 이제 차이점을 리뷰해 보겠습니다. 기억하시겠지만, 일반적인 Transformer에서는 인코더 부분과 디코더 부분이 있습니다. 여기에서 강조해 보겠습니다.

이 부분이 인코더이고, 오른쪽 부분이 디코더입니다. 반면에 LLaMA에서는 디코더만 있습니다. 이는 LLaMA가 대형 언어 모델이기 때문인데, 다음 토큰 예측 작업으로 학습되었기 때문입니다. 

그래서 우리는 다음 토큰을 예측하기 위해 Self-Attention만 필요합니다. 이 모든 개념들을 자세히 살펴볼 것입니다. 즉, 다음 예측 작업이 무엇인지, 어떻게 작동하는지, 새로운 Self-Attention이 어떻게 작동하는지 등을 볼 것입니다.

그림에서 볼 수 있는 두 번째 차이점은 우리가 여기에서 임베딩을 가지고 있고, 원래의 Transformer에서도 임베딩을 가지고 있다는 것입니다. 그러나 임베딩 바로 다음에 포지셔널 인코딩이 아니라 RMSNorm이 있습니다. 실제로 모든 정규화가 블록들 앞에 이동했습니다. 이전에는 Multi-Head Attention이 있었고, 그 다음에 Layer Norm이 있었습니다. 여기서 이 플러스 기호는 스킵 커넥션과 Multi-Head Attention의 출력 그리고 정규화를 합친 것입니다. 그리고 여기, 여기, 여기서도 이 정규화가 있습니다. 즉, 매 블록 뒤에 있었습니다. 하지만 LLaMA에서는 매 블록 앞에 있습니다. 우리는 정규화가 무엇인지, 왜 그런 방식으로 작동하는지도 살펴볼 것입니다.

정규화 바로 다음에는 Self-Attention을 위한 Query, Key, Value의 입력이 있습니다. 한 가지 주목할 점은 포지셔널 인코딩이 더 이상 Transformer의 포지셔널 인코딩이 아니라 Rotary Positional Embedding이 되었다는 것입니다. 그리고 이것은 Query와 Key에만 적용되고 Value에는 적용되지 않습니다. 그 이유도 살펴볼 것입니다.

또 다른 점은 Self-Attention이 이제 KV 캐시를 사용하는 Self-Attention이라는 것입니다. KV 캐시가 무엇이고 어떻게 작동하는지도 알아볼 것입니다. 또한 Grouped Query Attention도 있습니다.

변경된 또 다른 것은 Feed Forward 레이어입니다. 일반적인 Transformer의 Feed Forward 레이어에서는 ReLU 활성화 함수를 사용했지만, LLaMA에서는 SwiGLU 함수를 사용합니다. 그 이유도 살펴볼 것입니다.

여기서 'N×'는 점선 안의 이 블록이 N번 반복된다는 것을 의미합니다. 마지막 레이어의 출력은 RMSNorm을 거쳐 Linear 레이어로, 그 후 Softmax로 전달됩니다. 우리는 이 블록들의 각 부분을 아래에서부터 구축해 볼 것입니다. 즉, 이 블록들이 무엇을 하는지, 어떻게 작동하는지, 서로 어떻게 상호작용하는지, 이 뒤에 어떤 수학이 있는지, 그들이 해결하려는 문제가 무엇인지 자세히 보여드릴 것입니다. 그래서 우리는 이 모델에 대한 깊은 지식을 갖게 될 것입니다.

**LLaMA 1**

이제 LLaMA가 소개한 모델들을 리뷰하는 것으로 여정을 시작해 봅시다. LLaMA 1은 2023년 2월에 나왔으며, 이 모델에 대해 네 가지 크기를 제공했습니다. 6.7억 매개변수, 130억, 330억, 650억이 있습니다. 그리고 이 숫자들이 무엇을 의미하는지 알아보겠습니다.

여기서 Dimension은 임베딩 벡터의 크기를 나타냅니다. 여기에서 볼 수 있듯이, 우리는 이후에 리뷰할 Input Embeddings를 가지고 있습니다. 이는 기본적으로 각 토큰을 이 Dimension으로 표시된 크기의 벡터로 변환합니다. 그 다음으로는 Head의 수가 있습니다. Attention에서 몇 개의 헤드를 사용하는지, 레이어의 수 등이 있습니다. 원래 Transformer에서는 Dimension이 512였고, Head의 수는 8개, 레이어의 수는 6개였던 것으로 기억합니다. 그리고 각 모델이 학습된 토큰의 수가 있습니다. LLaMA 2에서는 대부분의 숫자가 두 배로 증가했습니다. 컨텍스트 길이는 기본적으로 시퀀스 길이이며, 모델에 공급될 수 있는 가장 긴 시퀀스입니다. 그리고 모델이 학습된 토큰의 수도 두 배로 증가하여 각 모델 크기마다 1조에서 2조로 늘어났습니다. 매개변수는 거의 동일하게 유지되었습니다.

그 다음으로 'GQA'라는 컬럼이 있는데, 이는 이 두 가지 모델 크기인 340억과 700억이 Grouped Query Attention을 사용한다는 것을 나타냅니다. 이것이 어떻게 작동하는지도 살펴볼 것입니다.

**Input Embeddings**

이제 임베딩 레이어가 무엇인지 리뷰해 보겠습니다. 이를 위해 이전 비디오의 슬라이드를 사용하겠습니다. 이전 비디오에서 우리는 임베딩을 이렇게 소개했습니다. 단어 6개로 이루어진 문장이 있습니다. 우리는 이 문장을 토크나이즈합니다. 즉, 토큰으로 변환합니다. 토크나이즈는 보통 공백이 아니라 BPE 토크나이저로 수행됩니다. 따라서 실제로 각 단어는 서브워드로 분리됩니다. 하지만 간단히 하기 위해 우리는 공백을 구분자로 사용하여 문장을 토크나이즈합니다. 각 토큰은 다른 토큰과 공백으로 분리되어 있고, 각 토큰은 어휘집에서의 위치에 매핑됩니다. 어휘집은 모델이 인식하는 단어들의 목록이며, 꼭 단어일 필요는 없습니다. 그들은 그냥 토큰입니다. 그래서 각 토큰은 어휘집에서의 위치를 차지하고, 입력은 각 토큰이 어휘집에서 차지하는 번호를 나타냅니다.

그런 다음 우리는 각 입력 ID를 원래 Transformer에서는 크기 512의 벡터로 매핑하지만, LLaMA에서는 4096으로 매핑합니다. 이 임베딩은 학습 가능한 벡터이며, 모델의 매개변수입니다. 모델이 학습되는 동안 이 임베딩은 변경되어 자신이 매핑하는 단어의 의미를 포착하게 됩니다. 예를 들어, '고양이'와 '개'라는 단어는 유사한 임베딩을 가지길 바랍니다. 왜냐하면 같은 의미적 그룹에 속하기 때문입니다. 또한 '집'과 '빌딩'이라는 단어도 임베딩 벡터가 매우 가까울 것입니다. 이것이 임베딩의 아이디어입니다.

**정규화 및 RMSNorm**

이제 임베딩 바로 다음에 있는 정규화가 무엇인지 확인해 보겠습니다. 이를 위해 신경망이 어떻게 작동하는지 다시 살펴보겠습니다.

피드 포워드 신경망이 있다고 가정해 봅시다. 입력이 있고, 뉴런으로 이루어진 은닉층이 있습니다. 또 다른 은닉층이 있으며, 그 후 출력으로 매핑됩니다. 우리는 보통 타깃을 가지고 있고, 출력과 타깃을 비교하여 손실을 생성합니다. 손실은 역전파를 통해 두 개의 은닉층으로 전달됩니다. 즉, 손실에 대한 각 은닉층의 가중치에 대한 그라디언트를 계산하고, 설정한 학습률에 따라 이 가중치를 수정합니다.

왜 정규화가 필요한지, 정규화의 필요성을 확인하기 위해 신경망을 단순화해 보겠습니다. 우리의 신경망이 실제로 전화기를 만드는 공장이라고 가정해 봅시다. 전화기를 만들기 위해 우리는 원자재로 시작하여, 이를 하드웨어 팀에 제공합니다. 하드웨어 팀은 원자재를 받아 하드웨어를 생산합니다. 예를 들어, 블루투스 장치를 선택하고, 디스플레이를 선택하고, 마이크와 카메라 등을 선택하여 이 전화기의 하드웨어를 구성합니다. 하드웨어 팀은 이 프로토타입을 소프트웨어 팀에 전달하고, 소프트웨어 팀은 이 하드웨어를 위한 소프트웨어를 만듭니다. 그리고 소프트웨어 팀의 출력은 하드웨어와 소프트웨어가 포함된 완성된 전화기가 됩니다.

출력은 원래의 전화기 디자인과 비교되고, 손실을 계산합니다. 즉, 우리가 목표로 했던 전화기와 실제로 생산된 것의 차이를 확인합니다. 손실이 크다면, CEO인 손실은 하드웨어 팀과 소프트웨어 팀과 대화하여 다음 번에는 목표에 더 가까워지도록 전략을 조정하도록 요청합니다. 예를 들어, 하드웨어가 너무 비쌌다면, CEO는 하드웨어 팀에게 더 작은 디스플레이를 사용하고, 더 저렴한 카메라를 사용하고, 블루투스를 저전력으로 변경하고, 와이파이를 저에너지로 변경하고, 배터리를 조정하도록 요청할 것입니다. 또한 소프트웨어 팀과도 전략을 조정하여 리팩토링에 덜 집중하고, 트레이닝에 덜 집중하고, 인턴을 더 많이 고용하고, 직원에 대해 너무 많이 신경 쓰지 말라고 요청할 것입니다.

그 다음으로 다시 원자재로 돌아가서 시작합니다. 하드웨어 팀은 CEO가 설정한 새로운 전략에 따라 새로운 하드웨어를 생산합니다. 이제 문제가 발생합니다. 소프트웨어 팀은 이전에 본 적 없는 하드웨어를 받게 됩니다. 디스플레이가 변경되고, 블루투스가 변경되고, 와이파이가 변경되는 등 모든 것이 변경되었기 때문입니다. 따라서 소프트웨어 팀은 많은 작업을 다시 해야 합니다. 특히 그들의 전략을 많이 조정해야 합니다. 이전에 본 적 없는 것들을 다루고 있기 때문입니다. 그래서 많은 시간과 자원을 낭비하게 될 수 있으며, 목표에 더 가까워지기는커녕 도달조차 하지 못할 수도 있습니다. 이번에는 손실이 더 클 수도 있습니다.

이처럼 문제는 손실 함수가 하드웨어 팀과 소프트웨어 팀의 가중치를 수정하지만, 소프트웨어 팀은 다음 반복에서 이전에 본 적 없는 입력을 받게 되고, 이는 이전에 생산했던 것과 상당히 다른 출력을 만들어냅니다. 이는 모델의 손실을 진동시키고, 학습을 매우 느리게 만듭니다.

이제 정규화가 어떻게 작동하는지 이해하기 위해 수학적으로 어떤 일이 일어나는지 살펴보겠습니다. 몇 가지 수학을 리뷰해 봅시다. nn.Linear로 정의된 선형 레이어가 있다고 가정해 봅시다. 입력 특징이 3개이고, 출력 특징이 5개이며, 편향을 사용합니다. 이는 PyTorch에서 정의된 선형 레이어입니다. 선형 레이어는 가중치인 W와 편향인 b라는 두 개의 행렬을 만듭니다. 입력 X의 모양이 10행 3열이라고 가정해 봅시다. 이 입력 X에 대한 선형 레이어의 출력은 10행 5열이 됩니다.

이것이 수학적으로 어떻게 일어나는지 살펴보겠습니다. 우리의 입력은 10×3이며, 이는 10개의 아이템이 있고 각 아이템이 3개의 특징을 가진다는 것을 의미합니다. 선형 레이어에 의해 생성된 W 행렬은 5×3입니다. 즉, 출력 특징 수 × 입력 특징 수입니다. 우리는 이 행렬의 각 행을 하나의 뉴런으로 생각할 수 있습니다. 각 뉴런은 입력 X의 각 특징에 대한 3개의 가중치를 갖습니다. 그 다음으로 편향 벡터가 있습니다. 편향 벡터는 각 뉴런에 하나의 가중치를 가지며, 이는 모든 뉴런에 하나씩 있기 때문입니다. 이는 10×5의 출력을 생성하며, 이는 10개의 아이템이 있고 각 아이템이 5개의 특징을 가진다는 것을 의미합니다.

이 행렬에서 정보의 흐름이 어떻게 되는지 이해해 봅시다. 정보의 흐름은 다음 식에 의해 지배됩니다: 출력은 X와 W 행렬의 전치행렬의 곱에 b를 더한 것입니다. 입력 X가 있고, 아이템 1이 있으며, 아이템 1은 특징 A1, A2, A3을 가집니다. Wᵗ의 전치행렬은 행과 열을 교환한 이 행렬입니다. 우리는 두 행렬을 곱하여 이 행렬을 얻습니다. 여기서 행렬의 첫 번째 행은 이 행 벡터와 이 열 벡터의 내적입니다. 그런 다음 편향 벡터 b를 더합니다. 두 행렬을 더하기 위해서는 동일한 차원을 가져야 하지만, PyTorch에서는 브로드캐스팅 덕분에 이 행 벡터가 각 행에 개별적으로 더해집니다. 그러면 다음과 같은 출력을 얻게 되며, 첫 번째 아이템은 Z1이 됩니다. Z1은 R1에 b1을 더한 것이며, R1은 이 열과 이 행의 내적입니다. 즉, 아이템 1에 대한 뉴런 1의 출력은 아이템 1의 특징에만 의존합니다.

보통 이 출력 후에 ReLU 함수와 같은 비선형성을 적용하며, ReLU 함수의 인자를 뉴런 1의 활성화라고 합니다. 여기서 볼 수 있듯이, 뉴런 1의 출력은 각 아이템의 입력 특징에만 의존합니다. 데이터 아이템에 대한 요소의 출력은 입력 데이터 아이템의 특징과 뉴런의 매개변수에 의존합니다.

입력 X를 이전 레이어의 출력으로 생각할 수 있습니다. 예를 들어, 이전 레이어 이후에 그라디언트 하강법으로 가중치가 업데이트되면, 이전 레이어의 출력이 크게 변경될 수 있습니다. 이는 우리가 앞서 했던 것처럼, CEO가 하드웨어 팀의 전략을 조정했기 때문입니다. 이전 레이어인 하드웨어 팀은 이전에 생산했던 것과 크게 다른 출력을 생산하게 됩니다. 다음 레이어는 출력도 크게 변경됩니다. 이는 손실 함수에 정의된 전략에 부합하기 위해 다음 단계의 그라디언트 하강법에서 가중치를 크게 다시 조정해야 하기 때문입니다.

우리가 좋아하지 않는 것은 이전 레이어의 출력이 너무 많이 변경되어 다음 레이어도 출력을 많이 변경해야 하는 상황입니다. 이로 인해 모델의 학습이 매우 느려지고 손실 함수가 진동하게 됩니다. 뉴런의 내부 노드의 분포가 변경되는 이러한 현상을 내부 공변량 변화(Internal Covariate Shift)라고 하며, 우리는 이를 피하고자 합니다.