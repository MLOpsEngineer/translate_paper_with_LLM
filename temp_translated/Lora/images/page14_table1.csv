0
"Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, and Andrea Montanari. When do neural"
"networks outperform kernel methods? arXiv preprint arXiv:2006.13409, 2020."
"Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. Samsum corpus: A human-"
"annotated dialogue dataset for abstractive summarization. CoRR, abs/1911.12237, 2019. URL"
http://arxiv.org/abs/1911.12237.
"Lars Grasedyck, Daniel Kressner, and Christine Tobler.
A literature survey of
low-rank tensor"
"approximation techniques. GAMM-Mitteilungen, 36(1):53–78, 2013."
Jihun Ham and Daniel D. Lee. Grassmann discriminant analysis: a unifying view on subspace-based
"learning.
In ICML, pp. 376–383, 2008.
URL https://doi.org/10.1145/1390156."
1390204.
"Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. WARP: Word-level Adversarial"
"ReProgramming. arXiv:2101.00121 [cs], December 2020. URL http://arxiv.org/abs/"
2101.00121. arXiv: 2101.00121.
"Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. Deberta: Decoding-enhanced bert"
"with disentangled attention, 2021."
"Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe,"
"Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
Parameter-Efﬁcient Transfer Learning"
"for NLP.
arXiv:1902.00751 [cs, stat], June 2019. URL http://arxiv.org/abs/1902."
00751.
"Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Speeding up convolutional neural networks"
"with low rank expansions. arXiv preprint arXiv:1405.3866, 2014."
"Mikhail Khodak, Neil Tenenholtz, Lester Mackey, and Nicol`o Fusi. Initialization and regularization"
"of factorized neural layers, 2021."
"Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017."
"Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang,"
"Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional"
"computation and automatic sharding, 2020."
"Brian Lester, Rami Al-Rfou, and Noah Constant. The Power of Scale for Parameter-Efﬁcient Prompt"
"Tuning. arXiv:2104.08691 [cs], April 2021. URL http://arxiv.org/abs/2104.08691."
arXiv: 2104.08691.
"Chunyuan Li, Heerad Farkhoor, Rosanne Liu, and Jason Yosinski. Measuring the Intrinsic Di-"
"arXiv:1804.08838 [cs,
mension of Objective Landscapes.
stat], April 2018a.
URL http:"
//arxiv.org/abs/1804.08838. arXiv: 1804.08838.
"Xiang Lisa Li and Percy Liang.
Preﬁx-Tuning: Optimizing Continuous Prompts for Generation."
"arXiv:2101.00190 [cs], January 2021. URL http://arxiv.org/abs/2101.00190."
Yuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gradient
"descent on structured data.
In Advances in Neural Information Processing Systems, 2018."
"Yuanzhi Li, Yingyu Liang, and Andrej Risteski.
Recovery guarantee of weighted low-rank ap-"
"proximation via alternating minimization. In International Conference on Machine Learning, pp."
"2358–2367. PMLR, 2016."
"Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized"
"matrix sensing and neural networks with quadratic activations.
In Conference On Learning The-"
"ory, pp. 2–47. PMLR, 2018b."
"Zhaojiang Lin, Andrea Madotto, and Pascale Fung. Exploring versatile generative language model"
"the Association for Computational Lin-
via parameter-efﬁcient
transfer learning.
In Findings of"
"guistics: EMNLP 2020, pp. 441–459, Online, November 2020. Association for Computational"
"Linguistics.
doi:
10.18653/v1/2020.ﬁndings-emnlp.41.
URL https://aclanthology."
org/2020.findings-emnlp.41.
