그리고 STS-B (텍스트 유사도, Cer 등 (2017)). 이 광범위한 커버리지로 인해 GLUE 벤치마크는 RoBERTa와 DeBERTa와 같은 NLU 모델을 평가하는 표준 지표가 되었습니다. 개별 데이터셋은 각기 다른 허용 라이선스 하에 공개되었습니다. 

WikiSQL은 Zhong 등 (2017)에서 소개되었으며, 56,355개의 학습 예제와 8,421개의 검증 예제를 포함하고 있습니다. 이 작업의 목표는 자연어 질문과 테이블 스키마로부터 SQL 쿼리를 생성하는 것입니다. 우리는 컨텍스트를 x = {테이블 스키마, 쿼리}로, 타겟을 y = {SQL}로 인코딩합니다. 이 데이터셋은 BSD 3-Clause License 하에 공개되었습니다.

SAMSum은 Gliwa 등 (2019)에서 소개되었으며, 14,732개의 학습 예제와 819개의 테스트 예제를 포함하고 있습니다. 이는 두 사람 사이의 연극화된 채팅 대화와 언어학자가 작성한 해당 요약문으로 구성되어 있습니다. 우리는 컨텍스트를 "\n"으로 연결된 발화문에 이어 "\n\n"을 붙여 인코딩하고, 타겟을 y = {요약}으로 인코딩합니다. 이 데이터셋은 비상업적 라이선스인 Creative Commons BY-NC-ND 4.0 하에 공개되었습니다.

E2E NLG Challenge는 처음으로 Novikova 등 (2017)에서 소개되었으며, end-to-end, 데이터 기반의 자연어 생성 시스템을 학습하기 위한 데이터셋으로 사용되며, 데이터-텍스트 평가에 일반적으로 사용됩니다. E2E 데이터셋은 대략 42,000개의 학습, 4,600개의 검증, 그리고 4,600개의 테스트 예제로 구성되어 있으며, 이는 모두 레스토랑 도메인에서 추출되었습니다. 각 입력 소스 테이블은 여러 참조를 가질 수 있습니다. 각 샘플 입력 (x,y)은 슬롯-값 쌍의 시퀀스와 함께 해당하는 자연어 참조 텍스트로 구성되어 있습니다. 이 데이터셋은 Creative Commons BY-NC-SA 4.0 하에 공개되었습니다.

DART는 Nan 등 (2020)에서 설명된 오픈 도메인 데이터-텍스트 데이터셋입니다. DART 입력은 ENTITY - RELATION - ENTITY 삼중체의 시퀀스로 구성되어 있습니다. 총 82K개의 예제로, DART는 E2E에 비해 훨씬 크고 복잡한 데이터-텍스트 작업입니다. 이 데이터셋은 MIT 라이선스 하에 공개되었습니다.

WebNLG는 또 다른 데이터-텍스트 평가에 일반적으로 사용되는 데이터셋입니다(Gardent 등, 2017). 총 22K개의 예제로, WebNLG는 14개의 고유한 카테고리를 포함하며, 이 중 9개는 학습 중에 볼 수 있습니다. 총 14개의 카테고리 중 5개는 학습 중에는 보이지 않지만 테스트 세트에 표시되므로, 평가는 일반적으로 "보인" 카테고리 (S), "보이지 않은" 카테고리 (U) 그리고 "모든" (A) 카테고리로 나누어 진행됩니다. 각 입력 예제는 SUBJECT - PROPERTY - OBJECT 삼중체의 시퀀스로 표현됩니다. 이 데이터셋은 Creative Commons BY-NC-SA 4.0 하에 공개되었습니다.

## 실험에서 사용된 하이퍼파라미터

### D.1 ROBERTA

우리는 AdamW를 사용하여 선형 학습률 감소 스케줄로 학습합니다. 우리는 LoRA의 학습률, 학습 에폭 수, 그리고 배치 크기를 조정합니다. Liu 등 (2019)을 따라, 우리는 MRPC, RTE, 그리고 STS-B에 적응할 때 LoRA 모듈을 MNLI 체크포인트로 초기화합니다, 이는 일반적인 초기화 방법이 아닙니다; 사전 학습된 모델은 모든 작업에 대해 고정되어 있습니다. 우리는 5개의 랜덤 시드에 대한 중앙값을 보고합니다; 각 실행의 결과는 최적의 에폭에서 얻어집니다. Houlsby 등 (2019)과 Pfeiffer 등 (2021)의 설정과 공정한 비교를 위해, 우리는 모델의 시퀀스 길이를 128로 제한하고 모든 작업에 대해 고정 배치 크기를 사용합니다. 중요한 점은, 우리가 MRPC, RTE, 그리고 STS-B에 적응할 때, 이미 MNLI에 적응한 모델이 아닌 사전 학습된 RoBERTa large 모델로 시작한다는 것입니다. 이 제한된 설정으로 실행된 결과는 †로 표시됩니다. 우리의 실행에서 사용된 하이퍼파라미터는 표 9에서 확인할 수 있습니다.

### D.2 DEBERTA

우리는 다시 AdamW를 사용하여 선형 학습률 감소 스케줄로 학습합니다. He 등 (2021)을 따라, 우리는 학습률, 드롭아웃 확률, 웜업 스텝, 그리고 배치 크기를 조정합니다. 우리는 He 등 (2021)이 사용한 것과 동일한 모델 시퀀스 길이를 사용하여 비교가 공정하도록 합니다. He 등 (2021)을 따라, 우리는 MRPC, RTE, 그리고 STS-B에 적응할 때 LoRA 모듈을 MNLI 체크포인트로 초기화합니다, 이는 일반적인 초기화 방법이 아닙니다; 사전 학습된 모델은 모든 작업에 대해 고정되어 있습니다. 우리는 5개의 랜덤 시드에 대한 중앙값을 보고합니다; 각 실행의 결과는 최적의 에폭에서 얻어집니다. 우리의 실행에서 사용된 하이퍼파라미터는 표 10에서 확인할 수 있습니다.

[TABLE: page18_table1.png]