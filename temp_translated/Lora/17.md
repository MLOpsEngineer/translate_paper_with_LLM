방법 MNLI-m(검증 정확도/%) RTE(검증 정확도/%)
GPT-3Few-Shot 40.6 69.0
GPT-3Fine-Tuned 89.5 85.4
표8: GPT-3(Brown 등., 2020)에서는 Fine-tuning이 Few-shot 학습을 크게 앞섭니다.

B 추론 지연 시간: 어댑터 레이어에 의한
어댑터 레이어는 사전 훈련된 모델에 순차적으로 추가되는 외부 모듈이며, 반면에 우리의 제안인 LoRA는 병렬적으로 추가되는 외부 모듈로 볼 수 있습니다. 따라서 어댑터 레이어는 기본 모델 외에도 계산되어야 하므로, 추가적인 지연 시간을 불가피하게 도입합니다. Ru¨ckle´ 등.(2020)에서 지적한 것처럼, 모델 배치 크기와/또는 시퀀스 길이가 하드웨어 병렬성을 충분히 활용할 수 있을 정도로 크면 어댑터 레이어에 의해 도입된 지연 시간을 완화할 수 있습니다. 우리는 GPT-2 중간 크기 모델에서 비슷한 지연 시간 연구를 통해 이러한 관찰을 확인하고, 배치 크기가 작은 온라인 추론과 같이 추가된 지연 시간이 상당히 큰 시나리오가 있다는 점을 지적합니다.
우리는 NVIDIA Quadro RTX8000에서 단일 포워드 패스의 지연 시간을 100회 시행의 평균으로 측정합니다. 우리는 입력 배치 크기, 시퀀스 길이, 그리고 어댑터 병목 차원 r을 변화시킵니다. 우리는 두 가지 어댑터 디자인을 테스트합니다: Houlsby 등.(2019)에 의한 원래의 것을 AdapterH라고 부르고, Lin 등.(2020)에 의한 최근의 더 효율적인 변형을 AdapterL이라고 부릅니다. 디자인에 대한 자세한 내용은 5.1절을 참조하십시오. 우리는 어댑터가 없는 기준에 비해 느려진 비율을 그림 5에 표시합니다.

그림5: 어댑터가 없는 (r = 0) 기준에 비해 추론 지연 시간의 백분율 느려짐. 상단 행은 AdapterH의 결과를 보여주고, 하단 행은 AdapterL을 보여줍니다. 더 큰 배치 크기와 시퀀스 길이는 지연 시간을 완화하는 데 도움이 되지만, 온라인, 짧은 시퀀스 길이 시나리오에서는 느려짐이 30% 이상이 될 수 있습니다. 우리는 더 나은 가시성을 위해 컬러맵을 조정합니다.

C 데이터셋 세부 사항
GLUE 벤치마크는 자연어 이해 작업의 광범위한 컬렉션입니다. 이에는 MNLI(추론, Williams 등.(2018)), SST-2(감성 분석, Socher 등.(2013)), MRPC(패러프레이즈 감지, Dolan & Brockett (2005)), CoLA(언어적 수용성, Warstadt 등.(2018)), QNLI(추론, Rajpurkar 등.(2018)), QQP8(질문-답변), RTE(추론) 등이 포함됩니다.