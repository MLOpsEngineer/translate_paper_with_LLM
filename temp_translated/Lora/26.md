**번역:**

1
7
13
19 0.8 25 31 0.7
37
43 0.6
49
55 0.5
61
0.4
0.3
0.2
0.1
0.0
1번 레이어 i
Wq Wv
23번 레이어
Wq Wv
1 6 11 61 12 62 13 63 14 64 15 65 16
1
7
13
19
25
31
37
43
49
55
61
j
46
i번 레이어
1 6 11 61 12 62 13 63 14 64 15 65 16
j
1 6 11 61 12 62 13 63 14 64 15 65 16
j
69
레이어
1 6 11 61 12 62 13 63 14 64 15 65 16
(Ar=64,A0r=64,i,j)
j
그림 7: 두 개의 무작위로 시드된 실행에서 A의 열 벡터 사이의 정규화된 부분 공간 유사성, 1번, 32번, 64번, 그리고 96번 레이어에서의 ∆Wq와 ∆Wv를 모두 포함하여, 96-레이어 트랜스포머에서.
Rankr val loss BLEU NIST METEOR ROUGE L CIDEr
1 1.23 68.72 8.7215 0.4565 0.7052 2.4329
2 1.21 69.17 8.7413 0.4590 0.7052 2.4639
4 1.18 70.38 8.8439 0.4689 0.7186 2.5349
8 1.17 69.57 8.7457 0.4636 0.7196 2.5196
16 1.16 69.61 8.7483 0.4629 0.7177 2.4985
32 1.16 69.33 8.7736 0.4642 0.7105 2.5255
64 1.16 69.24 8.7174 0.4651 0.7180 2.5070
128 1.16 68.73 8.6718 0.4628 0.7127 2.5030
256 1.16 68.92 8.6982 0.4629 0.7128 2.5012
512 1.16 68.78 8.6857 0.4637 0.7128 2.5025
1024 1.17 69.37 8.7495 0.4659 0.7149 2.5090
표 18: LoRA가 GPT-2 Medium에서 다양한 rank r을 사용하여 E2E NLG Challenge에서 달성한 검증 손실과 테스트 세트 메트릭. GPT-3에서는 r = 1이 많은 작업에 충분하지만, 여기서는 검증 손실에 대해 r = 16에서, BLEU에 대해 r = 4에서 성능이 최고점을 찍음을 보여줍니다. 이는 GPT-2 Medium이 GPT-3175B와 비교하여 적응에 대한 유사한 내재적 랭크를 가지고 있음을 제안합니다. 우리의 일부 하이퍼파라미터는 r = 4에서 조정되며, 이는 다른 기준선의 매개변수 수와 일치하므로, 다른 r의 선택에 대해 최적이지 않을 수 있음에 유의하십시오.
451
0.200
555
658 0.175
762
0.150
865
969 0.125
1072
0.100
1176
j
i
Wq 랜덤
(Wq,Ar=4,i,j) (Wq,Ar=8,i,j) (Wq,Ar=64,i,j) (Wq,Arand,i,j)
j j j
그림 8: Wq와 ∆Wq의 단일 방향 사이의 정규화된 부분 공간 유사성, r의 변화와 랜덤 기준선. ∆Wq는 Wq에서 강조되지 않은 중요한 방향을 증폭합니다. 더 큰 r을 가진 ∆Wq는 Wq에서 이미 강조된 더 많은 방향을 선택하는 경향이 있습니다.
26
[IMAGE: page26_image1.png]
[IMAGE: page26_image2.png]
[IMAGE: page26_image3.png]
[IMAGE: page26_image4.png]
[IMAGE: page26_image5.png]
[TABLE: page26_table1.png]
[TABLE: page26_table2.png]