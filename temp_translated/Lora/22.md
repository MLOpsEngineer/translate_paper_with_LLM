웹NLG 방법
BLEU↑ MET↑ TER↓
미국 미국 미국
GPT-2Medium
Fine-Tune(354M) 27.7 64.2 46.5 .30 .45 .38 .76 .33 .53
AdapterL(0.37M) 45.1 54.5 50.2 .36 .39 .38 .46 .40 .43
AdapterL(11M) 48.3 60.4 54.9 .38 .43 .41 .45 .35 .39
FTTop2(24M) 18.9 53.6 36.0 .23 .38 .31 .99 .49 .72
Prefix(0.35M) 45.6 62.9 55.1 .38 .44 .41 .49 .35 .40
LoRA(0.35M) 46.7 62.1 55.3 .38 .44 .41 .46 .33 .39
±.4 ±.2 ±.2
GPT-2Large
Fine-Tune(774M) 43.1 65.3 55.5 .38 .46 .42 .53 .33 .42
AdapterL(0.88M) 49.8 61.1 56.0 .38 .43 .41 .44 .35 .39
±.0 ±.0 ±.0
AdapterL(23M) 49.2 64.7 57.7 .39 .46 .43 .46 .33 .39
±.1 ±.2 ±.1
Prefix(0.77M) 47.7 63.4 56.3 .39 .45 .42 .48 .34 .40
LoRA(0.77M) 48.4 64.0 57.0 .39 .45 .42 .45 .32 .38
±.3 ±.3 ±.1
표14: 웹NLG에서 다양한 적응 방법을 사용한 GPT-2. MET와 TER의 분산은 모든 실험에서 0.01 미만입니다. "U"는 보이지 않는 카테고리를, "S"는 보이는 카테고리를, "A"는 웹NLG 테스트 세트의 모든 카테고리를 나타냅니다.

F.2 GPT-3에서의 추가 실험
표15에서는 GPT-3에서 다양한 적응 방법을 사용한 추가 실험을 제시합니다. 이는 성능과 훈련 가능한 매개변수의 수 사이의 트레이드오프를 확인하는 데 초점을 맞추고 있습니다.

F.3 저데이터 영역
저데이터 영역에서 다양한 적응 접근법의 성능을 평가하기 위해, 우리는 MNLI의 전체 훈련 세트에서 무작위로 100개, 1k개, 10k개의 훈련 예제를 샘플링하여 저데이터 MNLI-n 작업을 형성합니다. 표16에서는 MNLI-n에서 다양한 적응 접근법의 성능을 보여줍니다. 우리의 놀라움으로, PrefixEmbed와 PrefixLayer는 MNLI-100 데이터셋에서 매우 나쁜 성능을 보이며, PrefixEmbed는 무작위 선택(37.6% 대 33.3%)보다 약간 더 나은 성능을 보입니다. PrefixLayer는 PrefixEmbed보다는 더 나은 성능을 보이지만, MNLI-100에서 Fine-Tune이나 LoRA보다는 훨씬 나쁩니다. 훈련 예제의 수를 늘릴수록 prefix 기반 접근법과 LoRA/Fine-tuning 간의 차이는 줄어들며, 이는 prefix 기반 접근법이 GPT-3에서 저데이터 작업에 적합하지 않을 수 있음을 시사할 수 있습니다. LoRA는 MNLI-100과 MNLI-Full에서 Fine-tuning보다 더 나은 성능을 보이며, 무작위 시드로 인한 (±0.3)의 변동을 고려하면 MNLI-1k와 MNLI-10K에서 비슷한 결과를 보입니다.

MNLI-n에서 다양한 적응 접근법의 훈련 하이퍼파라미터는 표17에서 보고됩니다. 우리는 MNLI-100 세트에서 PrefixLayer에 대해 더 작은 학습률을 사용합니다. 이는 훈련 손실이 더 큰 학습률로 감소하지 않기 때문입니다.

G. 부분공간 간의 유사성 측정
이 논문에서는 우리는 φ(A,B,i,j)=ψ(Ui,Uj)= ||U Ai UB||2 F 를 사용하여 두 개의 열 정규 직교 행렬 Ui ∈ Rd×i 와 Uj ∈ Rd×j 간의 부분공간 유사성을 측정합니다. 이들은 A와 B의 왼쪽 특이 행렬의 열을 취함으로써 얻어집니다. 이 유사성은 단순히 부분공간 간의 거리를 측정하는 표준 투영 지표의 역수임을 지적하고 싶습니다(Ham & Lee, 2008).

22
[TABLE: page22_table1.png]
[TABLE: page22_table2.png]