웹NLG 방법론
표 14: 웹NLG 테스트 세트에서 다양한 적응 방법론을 사용한 GPT-2. MET와 TER의 분산은 모든 실험에서 0.01 미만입니다. "U"는 보이지 않는 카테고리를, "S"는 보이는 카테고리를, "A"는 웹NLG 테스트 세트의 모든 카테고리를 나타냅니다.

F.2 GPT-3에서의 추가 실험
표 15에서는 GPT-3에서 다양한 적응 방법론을 사용한 추가 실험을 제시합니다. 이는 성능과 훈련 가능한 매개변수의 수 사이의 트레이드오프를 확인하는 데 초점을 맞추고 있습니다.

F.3 저데이터 상황
저데이터 상황에서 다양한 적응 접근법의 성능을 평가하기 위해, 우리는 MNLI의 전체 훈련 세트에서 무작위로 100개, 1k개, 10k개의 훈련 예제를 샘플링하여 저데이터 MNLI-n 작업을 형성합니다. 표 16에서는 MNLI-n에서 다양한 적응 접근법의 성능을 보여줍니다. 놀랍게도, PrefixEmbed와 PrefixLayer는 MNLI-100 데이터셋에서 매우 나쁜 성능을 보이며, PrefixEmbed는 무작위 선택(37.6% 대 33.3%)보다 약간 더 나은 성능을 보입니다. PrefixLayer는 PrefixEmbed보다는 더 나은 성능을 보이지만, MNLI-100에서 Fine-Tune이나 LoRA보다는 훨씬 나쁩니다. 훈련 예제의 수를 늘릴수록 prefix 기반 접근법과 LoRA/Fine-tuning 간의 차이는 줄어들며, 이는 prefix 기반 접근법이 GPT-3에서 저데이터 작업에 적합하지 않을 수 있음을 시사할 수 있습니다. LoRA는 MNLI-100과 MNLI-Full에서 Fine-tuning보다 더 나은 성능을 보이며, 무작위 시드로 인한 (±0.3)의 분산을 고려할 때 MNLI-1k와 MNLI-10K에서 비슷한 결과를 보입니다.

MNLI-n에서 다양한 적응 접근법의 훈련 하이퍼파라미터는 표 17에 보고되어 있습니다. 우리는 MNLI-100 세트에서 PrefixLayer에 대해 더 작은 학습률을 사용하였는데, 이는 더 큰 학습률로는 훈련 손실이 감소하지 않기 때문입니다.

G. 부분 공간 간의 유사성 측정
이 논문에서는 우리는 두 개의 열 정규 직교 행렬 $$Ui \in Rd \times i$$와 $$Uj \in Rd \times j$$ 사이의 부분 공간 유사성을 측정하기 위해 $$\phi(A,B,i,j)=\psi(Ui,Uj)= ||U Ai^T UB||^2 F$$를 사용합니다. 이는 A와 B의 왼쪽 특이 행렬의 열을 취함으로써 얻어집니다. 우리는 이 유사성이 단순히 부분 공간 간의 거리를 측정하는 표준 투영 지표의 역임을 지적합니다(Ham & Lee, 2008).